# Sign-Language-Regonization-using-CNN-Algorithm-with-Meachine-Learning-Techniques-Paper
This repository contains the research paper and technical documentation for a Deep Learning system designed to translate visual sign language into text and audio. This project was presented at IIT Madras (IMPULSE 2k23).


# üìù Abstract
Communication hurdles for the deaf and hard-of-hearing community create an increasing demand for accessible technology. This project proposes a system that automatically decodes sign language gestures into spoken or written words. By utilizing Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks, the system handles the complexity and variety of hand motions to provide accurate real-time recognition.

# üöÄ Key Features
Multi-Stage Pipeline: Includes image preprocessing, feature extraction, and gesture detection.

Deep Learning Architecture: Utilizes CNNs for spatial feature extraction from video frames and LSTMs for temporal sequence recognition.

Dual Output: Translates recognized gestures into both Text and Audio formats to facilitate two-way communication.

# üõ†Ô∏è Technical Stack
- Language: Python 

- Neural Networks: Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM) 

- Libraries: (Commonly used in this research) TensorFlow/Keras, OpenCV, NumPy.

# üìÑ Presentation & Recognition
- Venue: Presented at IMPULSE 2k23, a national technical symposium hosted by IIT Madras.


# Authors: Akilan M. and Akila Lourdes.

Affiliation: Panimalar Engineering College, Chennai, India.

üìÇ Repository Structure
Sign Language Recognition...docx: Full research paper including methodology, literature review, and references
